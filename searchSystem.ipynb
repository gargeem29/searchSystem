{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsZXnAJugJm7",
        "outputId": "664707ab-44ec-4475-c54b-716077fd71b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.40.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (0.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok pandas numpy faiss-cpu sentence-transformers aiohttp requests tenacity\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import pickle\n",
        "import numpy as np\n",
        "import openai\n",
        "import aiohttp\n",
        "import asyncio\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import hashlib\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBqzK6pix_aV",
        "outputId": "067c2bbb-75b0-493d-c60a-62a96992c511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install together"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UR9jYJbP1Rf",
        "outputId": "c6f02baa-8f2b-48a0-a177-1e9c7bb46f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: together in /usr/local/lib/python3.10/dist-packages (1.3.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.10/dist-packages (from together) (3.10.10)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from together) (8.1.7)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from together) (0.2.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.10/dist-packages (from together) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from together) (1.26.4)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from together) (10.4.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from together) (17.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from together) (2.9.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.10/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from together) (4.66.6)\n",
            "Requirement already satisfied: typer<0.13,>=0.9 in /usr/local/lib/python3.10/dist-packages (from together) (0.12.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.9.3->together) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import pickle\n",
        "import numpy as np\n",
        "import openai\n",
        "import aiohttp\n",
        "import asyncio\n",
        "from together import AsyncTogether\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import hashlib\n",
        "from openai import OpenAI\n",
        "from together import Together\n",
        "\n",
        "openai.api_key = #\"your openai api key\"\n",
        "\n",
        "os.environ['TOGETHER_API_KEY'] = #\"your together api key\"\n",
        "# Initialize models for embeddings\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# FAISS Similarity Search\n",
        "def get_faiss_search_results(query, faiss_index, df):\n",
        "    # Generate embedding for the query\n",
        "    query_embedding = embedding_model.encode([query])[0]\n",
        "    query_embedding = np.array([query_embedding], dtype='float32')\n",
        "\n",
        "    # Perform FAISS search for top 5 similar entries\n",
        "    D, I = faiss_index.search(query_embedding, k=5)\n",
        "\n",
        "    # Collecting the top results from FAISS search\n",
        "    faiss_results = []\n",
        "    for idx in I[0]:\n",
        "        if idx < len(df):\n",
        "            faiss_results.append(df.iloc[idx].to_dict())  # Convert each row to a dictionary\n",
        "\n",
        "    return faiss_results\n",
        "\n",
        "# Function to handle file upload and create FAISS index dynamically\n",
        "def handle_file_upload(uploaded_file):\n",
        "    if uploaded_file is not None:\n",
        "        df = pd.read_csv(uploaded_file)\n",
        "        st.write(\"Preview of the uploaded CSV:\")\n",
        "        st.dataframe(df.head())\n",
        "\n",
        "        # Create a combined description column\n",
        "        description_columns = df.select_dtypes(include=['object']).columns\n",
        "        df['description'] = df[description_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "\n",
        "        # Generate embeddings and create FAISS index\n",
        "        descriptions = df['description'].tolist()\n",
        "        embeddings = embedding_model.encode(descriptions)\n",
        "\n",
        "        # Create FAISS index\n",
        "        dimension = embeddings.shape[1]\n",
        "        index = faiss.IndexFlatL2(dimension)\n",
        "        index.add(np.array(embeddings).astype('float32'))\n",
        "\n",
        "        # Save FAISS index and column data\n",
        "        with open('faiss_index.pkl', 'wb') as f:\n",
        "            pickle.dump(index, f)\n",
        "        with open('columns.pkl', 'wb') as f:\n",
        "            pickle.dump(df.columns.tolist(), f)\n",
        "\n",
        "        st.success(\"FAISS index created and saved successfully!\")\n",
        "        return df, index\n",
        "\n",
        "    return None, None\n",
        "\n",
        "API_KEY = #'your google search engine api key'\n",
        "CX = #'your cx key'\n",
        "\n",
        "# Cache dictionary to store results for reuse\n",
        "search_cache = {}\n",
        "\n",
        "# Function to get a hash for the search query to store results in cache\n",
        "def get_query_hash(query):\n",
        "    return hashlib.md5(query.encode()).hexdigest()\n",
        "\n",
        "# @retry(stop=stop_after_attempt(5), wait=wait_exponential(min=4, max=60))\n",
        "# async def expand_query_with_llm(query):\n",
        "#     # Create a more specific and detailed prompt for query expansion\n",
        "#     expanded_query_prompt = f\"Make the following query more specific and detailed but concise for a web search:\\n\\n'{query}'\"\n",
        "\n",
        "#     # Call LLM to expand the query\n",
        "#     response = await async_client.chat.completions.create(\n",
        "#         model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "#         messages=[\n",
        "#             {\"role\": \"system\", \"content\": \"You are a helpful assistant for search query expansion.\"},\n",
        "#             {\"role\": \"user\", \"content\": expanded_query_prompt}\n",
        "#         ],\n",
        "#         max_tokens=100\n",
        "#     )\n",
        "\n",
        "#     # Extract the expanded query from the LLM response, ensuring it's a single line\n",
        "#     expanded_query = response['choices'][0]['message']['content'].strip().replace(\"\\n\", \" \")\n",
        "\n",
        "#     return expanded_query\n",
        "\n",
        "\n",
        "# Function to make a web search request using Google Custom Search API\n",
        "async def fetch_web_data(query, session):\n",
        "    query_hash = get_query_hash(query)\n",
        "\n",
        "    # If the query result is cached, return it from the cache\n",
        "    if query_hash in search_cache:\n",
        "        return search_cache[query_hash]\n",
        "\n",
        "    # expanded_query = await expand_query_with_llm(query)\n",
        "    # st.write(f\"Expanded query: {expanded_query}\")\n",
        "\n",
        "    # encoded_query = urllib.parse.quote(expanded_query)\n",
        "    # st.write(f\"Expanded query: {encoded_query}\")\n",
        "\n",
        "    url = f'https://www.googleapis.com/customsearch/v1?q={query}&key={API_KEY}&cx={CX}'\n",
        "    st.write(f\"Search URL: {url}\")\n",
        "\n",
        "    try:\n",
        "        async with session.get(url) as response:\n",
        "            if response.status == 200:\n",
        "                data = await response.json()\n",
        "                if 'items' in data:\n",
        "                    results = [{\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item.get(\"snippet\", \"No snippet available\")} for item in data['items']]\n",
        "                    # Cache the result\n",
        "                    search_cache[query_hash] = results\n",
        "                    return results\n",
        "                else:\n",
        "                    return [{\"title\": \"No results found\", \"link\": \"\", \"snippet\": \"\"}]\n",
        "            else:\n",
        "                raise Exception(f\"Error fetching data: {response.status}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in fetching data: {e}\")\n",
        "        return []\n",
        "\n",
        "# Retry mechanism for async search queries\n",
        "@retry(stop=stop_after_attempt(5), wait=wait_exponential(min=4, max=60))\n",
        "async def async_search_queries(queries):\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        results = []\n",
        "        for query in queries:\n",
        "            result = await fetch_web_data(query, session)\n",
        "            results.append(result)\n",
        "            await asyncio.sleep(1)\n",
        "        return results\n",
        "\n",
        "# client = OpenAI(\n",
        "#     api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
        "# )\n",
        "# client = Together()\n",
        "\n",
        "# async def llm_extract_info(text, detailed=False):\n",
        "#     model_name = \"gpt-4\" if detailed else \"gpt-3.5-turbo\"\n",
        "\n",
        "#     response = await client.chat.completions.create(\n",
        "#     model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "#     messages = [\n",
        "#             {\"role\": \"system\", \"content\": \"Extract structured information from the following text.\"},\n",
        "#             {\"role\": \"user\", \"content\": text}\n",
        "#         ],\n",
        "#     )\n",
        "#     #max_tokens=150 if detailed else 50,\n",
        "#     return response['choices'][0]['message']['content']\n",
        "\n",
        "#     print(response._request_id)\n",
        "\n",
        "async_client = AsyncTogether(api_key=os.environ.get(\"TOGETHER_API_KEY\"))\n",
        "\n",
        "@retry(stop=stop_after_attempt(5), wait=wait_exponential(min=4, max=60))\n",
        "async def llm_extract_info(text, detailed=False):\n",
        "    model_name = \"meta-llama/Llama-3-70b-chat-hf\" if detailed else \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
        "\n",
        "    # Create async chat completion task\n",
        "    response = await async_client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Extract structured information from the following text.\"},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        max_tokens=150 if detailed else 50\n",
        "    )\n",
        "\n",
        "    # Extract and return the content\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# Define your Streamlit main function here\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"Enhanced Data Extraction Tool\", layout=\"wide\")\n",
        "    uploaded_file = st.file_uploader(\"Upload a CSV file\", type=[\"csv\"])\n",
        "\n",
        "    df = None\n",
        "    faiss_index = None\n",
        "\n",
        "    if uploaded_file:\n",
        "        df, faiss_index = handle_file_upload(uploaded_file)\n",
        "\n",
        "    if faiss_index is not None:\n",
        "        query = st.text_input(\"Enter search query:\")\n",
        "        if query:\n",
        "            async def run_query():\n",
        "                # FAISS Similarity Search\n",
        "                faiss_results = get_faiss_search_results(query, faiss_index, df)\n",
        "\n",
        "                # Async Web Search\n",
        "                web_search_results = await async_search_queries([query])\n",
        "\n",
        "                # LLM Extraction on FAISS and Web Results\n",
        "                # faiss_extractions = await asyncio.gather(*[llm_extract_info(str(result), detailed=True) for result in faiss_results])\n",
        "                # web_extractions = await asyncio.gather(*[llm_extract_info(str(result), detailed=True) for result in web_search_results])\n",
        "\n",
        "                faiss_extractions = []\n",
        "                for result in faiss_results:\n",
        "                    faiss_extractions.append(await llm_extract_info(str(result), detailed=True))\n",
        "                    await asyncio.sleep(1)  # Delay to prevent hitting rate limits\n",
        "\n",
        "                web_extractions = []\n",
        "                for result in web_search_results:\n",
        "                    web_extractions.append(await llm_extract_info(str(result), detailed=True))\n",
        "                    await asyncio.sleep(1)\n",
        "\n",
        "                # Compile all results into a DataFrame\n",
        "                structured_results = {\n",
        "                    \"Source\": [\"FAISS\"] * len(faiss_extractions) + [\"Web Search\"] * len(web_extractions),\n",
        "                    \"Query\": [query] * (len(faiss_extractions) + len(web_extractions)),\n",
        "                    \"Extracted Information\": faiss_extractions + web_extractions\n",
        "                }\n",
        "\n",
        "                results_df = pd.DataFrame(structured_results)\n",
        "\n",
        "                st.write(\"Structured Extraction Results:\")\n",
        "                st.dataframe(results_df)\n",
        "\n",
        "                # Download structured results as CSV\n",
        "                csv_data = results_df.to_csv(index=False)\n",
        "                st.download_button(\"Download Structured Data\", csv_data, \"extracted_data.csv\", \"text/csv\")\n",
        "\n",
        "            asyncio.run(run_query())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mITq-5AEpyzv",
        "outputId": "9b894c08-ec72-4c38-f4d7-31184d54650f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def run_streamlit():\n",
        "    # Start the Streamlit server in the background with the correct path to your saved script\n",
        "    os.system('streamlit run streamlit_app.py --server.enableCORS=false &')\n",
        "\n",
        "    # Set up the ngrok tunnel\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"Streamlit app is live at: {public_url}\")\n"
      ],
      "metadata": {
        "id": "YrXeWfOF2MY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken #enter your ngrok auth token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6ALk8UT3tFk",
        "outputId": "088ff044-c9fd-4c06-dcf3-671a8b5368c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_streamlit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhpD4Dpf2d9l",
        "outputId": "5cf500b7-c7ce-4ed6-e8b8-4a950d2f5a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://e904-34-106-20-10.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok\n"
      ],
      "metadata": {
        "id": "sHQayNCp4vOG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}